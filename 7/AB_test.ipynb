{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# load data\n",
    "df = pd.read_csv('herford_weather.csv')\n",
    "print(df.head())\n",
    "print(df.shape)\n",
    "\n",
    "# select features\n",
    "features = ['temperature_2m (°C)', 'relativehumidity_2m (%)', 'dewpoint_2m (°C)',\n",
    "            'apparent_temperature (°C)', 'pressure_msl (hPa)', 'surface_pressure (hPa)', \n",
    "            'precipitation (mm)', 'rain (mm)', 'snowfall (cm)',\n",
    "            'weathercode (wmo code)', 'cloudcover (%)', 'cloudcover_low (%)', \n",
    "            'cloudcover_mid (%)', 'cloudcover_high (%)', 'shortwave_radiation (W/m²)', \n",
    "            'direct_radiation (W/m²)', 'diffuse_radiation (W/m²)', \n",
    "            'direct_normal_irradiance (W/m²)', 'windspeed_10m (km/h)',\n",
    "            'windspeed_100m (km/h)', 'winddirection_10m (°)', 'winddirection_100m (°)', \n",
    "            'windgusts_10m (km/h)', 'et0_fao_evapotranspiration (mm)', \n",
    "            'vapor_pressure_deficit (kPa)', 'soil_temperature_0_to_7cm (°C)', \n",
    "            'soil_temperature_7_to_28cm (°C)', 'soil_temperature_28_to_100cm (°C)', \n",
    "            'soil_temperature_100_to_255cm (°C)', 'soil_moisture_0_to_7cm (m³/m³)',\n",
    "            'soil_moisture_7_to_28cm (m³/m³)', 'soil_moisture_28_to_100cm (m³/m³)', \n",
    "            'soil_moisture_100_to_255cm (m³/m³)']\n",
    "\n",
    "df_selected = df[features].copy()\n",
    "df_selected = df_selected.dropna()\n",
    "\n",
    "# dewpoint prediction\n",
    "target_dewpoint = 'dewpoint_2m (°C)'\n",
    "correlations_dewpoint = df_selected.corr()[target_dewpoint].abs().sort_values(ascending=False)\n",
    "print('\\ncorrelations with dewpoint:')\n",
    "print(correlations_dewpoint)\n",
    "\n",
    "# plot correlations\n",
    "plt.figure(figsize=(12, 8))\n",
    "top_features = correlations_dewpoint[1:16].index\n",
    "sns.heatmap(df_selected[list(top_features) + [target_dewpoint]].corr(), \n",
    "            annot=True, fmt='.2f', cmap='coolwarm', center=0)\n",
    "plt.title('correlation matrix dewpoint')\n",
    "plt.tight_layout()\n",
    "plt.savefig('correlation_dewpoint.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# select features with correlation > 0.3\n",
    "selected_features_dewpoint = correlations_dewpoint[(correlations_dewpoint > 0.3) & \n",
    "                                                   (correlations_dewpoint.index != target_dewpoint)].index.tolist()\n",
    "print('\\nselected features for dewpoint:')\n",
    "print(selected_features_dewpoint)\n",
    "\n",
    "# prepare data\n",
    "X_dewpoint = df_selected[selected_features_dewpoint]\n",
    "y_dewpoint = df_selected[target_dewpoint]\n",
    "\n",
    "X_train_dew, X_test_dew, y_train_dew, y_test_dew = train_test_split(\n",
    "    X_dewpoint, y_dewpoint, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# scaling\n",
    "scaler_dew = StandardScaler()\n",
    "X_train_dew_scaled = scaler_dew.fit_transform(X_train_dew)\n",
    "X_test_dew_scaled = scaler_dew.transform(X_test_dew)\n",
    "\n",
    "# build model\n",
    "model_dewpoint = keras.Sequential([\n",
    "    layers.Input(shape=(X_train_dew_scaled.shape[1],)),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "\n",
    "model_dewpoint.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "model_dewpoint.summary()\n",
    "\n",
    "# train\n",
    "epochs = 100\n",
    "batch_size = 32\n",
    "\n",
    "history_dewpoint = model_dewpoint.fit(\n",
    "    X_train_dew_scaled, y_train_dew,\n",
    "    validation_split=0.2,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# calculate r2\n",
    "y_pred_train_dew = model_dewpoint.predict(X_train_dew_scaled, verbose=0)\n",
    "y_pred_test_dew = model_dewpoint.predict(X_test_dew_scaled, verbose=0)\n",
    "\n",
    "r2_train_dew = r2_score(y_train_dew, y_pred_train_dew)\n",
    "r2_test_dew = r2_score(y_test_dew, y_pred_test_dew)\n",
    "\n",
    "print(f'\\ndewpoint results:')\n",
    "print(f'r2 train: {r2_train_dew:.4f}')\n",
    "print(f'r2 test: {r2_test_dew:.4f}')\n",
    "\n",
    "# plot learning curves\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "axes[0].plot(history_dewpoint.history['loss'], label='train loss')\n",
    "axes[0].plot(history_dewpoint.history['val_loss'], label='val loss')\n",
    "axes[0].set_xlabel('epoch')\n",
    "axes[0].set_ylabel('loss')\n",
    "axes[0].set_title('learning curve dewpoint loss')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].plot(history_dewpoint.history['mae'], label='train mae')\n",
    "axes[1].plot(history_dewpoint.history['val_mae'], label='val mae')\n",
    "axes[1].set_xlabel('epoch')\n",
    "axes[1].set_ylabel('mae')\n",
    "axes[1].set_title('learning curve dewpoint mae')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('learning_curves_dewpoint.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# snowfall prediction\n",
    "target_snowfall = 'snowfall (cm)'\n",
    "correlations_snowfall = df_selected.corr()[target_snowfall].abs().sort_values(ascending=False)\n",
    "print('\\ncorrelations with snowfall:')\n",
    "print(correlations_snowfall.head(15))\n",
    "\n",
    "selected_features_snowfall = correlations_snowfall[(correlations_snowfall > 0.1) & \n",
    "                                                   (correlations_snowfall.index != target_snowfall)].index.tolist()\n",
    "print('\\nselected features for snowfall:')\n",
    "print(selected_features_snowfall)\n",
    "\n",
    "if len(selected_features_snowfall) > 0:\n",
    "    X_snowfall = df_selected[selected_features_snowfall]\n",
    "    y_snowfall = df_selected[target_snowfall]\n",
    "    \n",
    "    X_train_snow, X_test_snow, y_train_snow, y_test_snow = train_test_split(\n",
    "        X_snowfall, y_snowfall, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    scaler_snow = StandardScaler()\n",
    "    X_train_snow_scaled = scaler_snow.fit_transform(X_train_snow)\n",
    "    X_test_snow_scaled = scaler_snow.transform(X_test_snow)\n",
    "    \n",
    "    model_snowfall = keras.Sequential([\n",
    "        layers.Input(shape=(X_train_snow_scaled.shape[1],)),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "    \n",
    "    model_snowfall.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "    \n",
    "    history_snowfall = model_snowfall.fit(\n",
    "        X_train_snow_scaled, y_train_snow,\n",
    "        validation_split=0.2,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    y_pred_train_snow = model_snowfall.predict(X_train_snow_scaled, verbose=0)\n",
    "    y_pred_test_snow = model_snowfall.predict(X_test_snow_scaled, verbose=0)\n",
    "    \n",
    "    r2_train_snow = r2_score(y_train_snow, y_pred_train_snow)\n",
    "    r2_test_snow = r2_score(y_test_snow, y_pred_test_snow)\n",
    "    \n",
    "    print(f'\\nsnowfall results:')\n",
    "    print(f'r2 train: {r2_train_snow:.4f}')\n",
    "    print(f'r2 test: {r2_test_snow:.4f}')\n",
    "    \n",
    "    print('\\nsnowfall statistics:')\n",
    "    print(y_snowfall.describe())\n",
    "    print(f'days with snow: {(y_snowfall > 0).sum() / len(y_snowfall) * 100:.2f}%')\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    axes[0].plot(history_snowfall.history['loss'], label='train loss')\n",
    "    axes[0].plot(history_snowfall.history['val_loss'], label='val loss')\n",
    "    axes[0].set_xlabel('epoch')\n",
    "    axes[0].set_ylabel('loss')\n",
    "    axes[0].set_title('learning curve snowfall loss')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    axes[1].plot(history_snowfall.history['mae'], label='train mae')\n",
    "    axes[1].plot(history_snowfall.history['val_mae'], label='val mae')\n",
    "    axes[1].set_xlabel('epoch')\n",
    "    axes[1].set_ylabel('mae')\n",
    "    axes[1].set_title('learning curve snowfall mae')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('learning_curves_snowfall.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print('\\nexplanation:')\n",
    "    print('snowfall prediction is worse than dewpoint because:')\n",
    "    print('- snowfall is rare event (mostly 0)')\n",
    "    print('- weak linear correlations')\n",
    "    print('- non-linear relationships')\n",
    "    print('- linear regression unsuitable for skewed data')\n",
    "else:\n",
    "    print('no features found')\n",
    "\n",
    "print('\\ndone')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
